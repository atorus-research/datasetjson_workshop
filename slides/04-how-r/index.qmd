---
title: "How to in R"
subtitle: "datasetjson - Read and write CDISC Dataset JSON formatted datasets in R and Python"
author: <code>R/Pharma 2025 Workshop</code>
date: 2025-11-07
logo: "../../images/sticker.svg"
footer: "[https://github.com/atorus-research/datasetjson_workshop](https://github.com/atorus-research/datasetjson_workshop)" 
editor: source
engine: knitr
format: 
  live-revealjs: 
    theme: ../slides.scss
    transition: fade
    slide-number: true
    chalkboard: true
execute:
  echo: true
  freeze: false
cache: false
---

{{< include ../../_extensions/r-wasm/live/_knitr.qmd >}}

## The Whole Game

Let's see the complete workflow with real ADAM data:

::: {.incremental}
1. **Start** with ADAM datasets (RDS/Parquet + metadata)
2. **Combine** data with metadata 
3. **Convert** to Dataset-JSON
4. **Share** the standardized file
5. **Read** it back anywhere
:::

---

## Step 1: Load ADAM Data and Metadata

```{r}
#| eval: true
library(datasetjson)

# Load data (RDS, Parquet, ... - your choice)
adsl <- readRDS("../../data/adam/adsl.rds")
# adsl <- arrow::read_parquet("adsl.parquet")

# Load metadata
adsl_meta <- readRDS("../../data/adam/metadata/adsl_meta.rds")
# adsl_meta <- arrow::read_parquet("adsl_meta.parquet")
```
---

## Step 2: Examine What We Have

```{r}
#| eval: true
# Clinical trial data
knitr::kable(
  head(adsl[1:6]),
  format = "html",
  table.attr = "style='font-size: 24px;'")
```

---

## Step 2: Examine What We Have

```{r}
#| eval: true
# Metadata follows Dataset-JSON spec
knitr::kable(
  head(adsl_meta),
  format = "html",
  table.attr = "style='font-size: 24px;'")
```

---

## Step 2: Examine What We Have
#### Data Type: float

```{r}
#| eval: true
# Clinical trial data
floats <- adsl_meta |>
  dplyr::filter(adsl_meta$dataType == "float")

knitr::kable(
  head(floats, 4),
  format = "html",
  table.attr = "style='font-size: 24px;'")
```
---

## Step 2: Examine What We Have
#### Data Type: datetime

```{r}
#| eval: true
# Clinical trial data
datetime <- adsl_meta |>
  dplyr::filter(adsl_meta$dataType == "datetime")

knitr::kable(
  head(datetime, 4),
  format = "html",
  table.attr = "style='font-size: 24px;'")
```

---

## Step 2: Examine What We Have
#### Data Type: date

```{r}
#| eval: true
# Clinical trial data
dates <- adsl_meta |>
  dplyr::filter(adsl_meta$dataType == "date")

knitr::kable(
  head(dates, 4),
  format = "html",
  table.attr = "style='font-size: 24px;'")
```

---

## Step 3: Create Dataset-JSON

```{r}
#| eval: true
# Convert ADSL to Dataset-JSON
adsl_json <- dataset_json(
  adsl,
  name = "ADSL", 
  dataset_label = "Subject Level Analysis Dataset",
  columns = adsl_meta
)
```

---

## Step 4: Inspect Dataset-JSON Object

```{r}
#| eval: true
# Convert ADSL to Dataset-JSON
head(adsl_json)
```

---

## Step 4: Inspect Dataset-JSON Object
#### Dataset-JSON Attributes

```{r}
#| eval: true
str(attributes(adsl_json)[c("label", "name", "columns")])
```

---

## Step 5: Share Standardized Files

```{r}
#| eval: true
# Write to Dataset-JSON files
write_dataset_json(adsl_json, "output/ADSL.json")
# write_dataset_json(adsl_json, "output/ADSL.json", pretty = TRUE) # use pretty when viewing

# Now anyone can read these files!
# - Regulatory reviewers
# - External collaborators  
# - Different software (R, Python, SAS)
```

---

## Step 6: Read Back Anywhere

```{r}
#| eval: true
# Read back - gets original data + metadata
adsl_restored <- read_dataset_json("output/ADSL.json")

adsl_restored
```

---

## Step 6: Read Back Anywhere

```{r}
#| eval: true
# Read back - gets original data + metadata
str(attributes(adsl_restored)[c("label", "name", "columns")])
```

---

## Compare Original and Restored

```{r}
#| eval: true
# Identical to original
diffdf::diffdf(adsl, adsl_restored)
```

---

## Compare Original and Restored

```{r}
#| eval: true
# compare class and attributes
waldo::compare(adsl, adsl_restored)
```

---

## Why This Matters

::: {.incremental}
- **Format agnostic**: Start with RDS, Parquet, CSV - doesn't matter
- **Metadata preserved**: Labels, types, all CDISC information
- **Standardized**: One format for sharing across tools/organizations
- **Validated**: Built-in schema validation
- **Round-trip safe**: _Almost_ Perfect data fidelity
:::

---

## Your Turn: Exercises

Now repeat the whole game with ADAE data! Open `exercises/01-r.R`:

::: {.incremental}
1. **Load ADAE** - Load data and metadata (RDS or Parquet)
2. **Examine** - Look at data types and structure
3. **Convert** - Create Dataset-JSON object
4. **Write** - Save to standardized file
5. **Read Back** - Verify round-trip fidelity
:::

## Exercise Preview

```{r}
#| eval: false
# Load ADAE data and metadata
adae <- readRDS("data/adam/adae.rds")
adae_meta <- readRDS("data/adam/metadata/adae_meta.rds")

# Follow the same steps as ADSL!
# Convert, write, read back, and compare
```

## Questions?

::: {.center}
Ready to dive into the exercises?

Open `exercises/01-r.R` and let's explore the datasetjson package together!
:::